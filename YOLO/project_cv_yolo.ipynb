{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "8D0EvzB18bSb",
    "outputId": "fbe9c231-e270-45e0-9a26-c23ad16256e3"
   },
   "source": [
    "# –ü—Ä–æ–µ–∫—Ç\n",
    "\n",
    "# –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –¥–æ—Ä–æ–∂–Ω—ã—Ö –∑–Ω–∞–∫–æ–≤\n",
    "\n",
    "### –ú–æ–¥–µ–ª—å YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in c:\\users\\1\\anaconda3\\lib\\site-packages (0.2.9)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: opencv-python in c:\\users\\1\\anaconda3\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: torch in c:\\users\\1\\anaconda3\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\1\\anaconda3\\lib\\site-packages (0.19.1)\n",
      "Requirement already satisfied: requests in c:\\users\\1\\anaconda3\\lib\\site-packages (from kagglehub) (2.24.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\1\\anaconda3\\lib\\site-packages (from kagglehub) (24.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\1\\anaconda3\\lib\\site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.17.3; python_version >= \"3.8\" in c:\\users\\1\\anaconda3\\lib\\site-packages (from opencv-python) (1.24.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\1\\anaconda3\\lib\\site-packages (from torch) (3.0.12)\n",
      "Requirement already satisfied: sympy in c:\\users\\1\\anaconda3\\lib\\site-packages (from torch) (1.6.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\1\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\1\\anaconda3\\lib\\site-packages (from torch) (0.8.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\1\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\1\\anaconda3\\lib\\site-packages (from torch) (2.11.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\1\\anaconda3\\lib\\site-packages (from torchvision) (8.0.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\1\\anaconda3\\lib\\site-packages (from requests->kagglehub) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\1\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\1\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\1\\anaconda3\\lib\\site-packages (from requests->kagglehub) (3.0.4)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\1\\anaconda3\\lib\\site-packages (from tqdm->kagglehub) (0.4.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\1\\anaconda3\\lib\\site-packages (from sympy->torch) (1.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\1\\anaconda3\\lib\\site-packages (from jinja2->torch) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "pip install kagglehub opencv-python torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gdMayMaI8d3B",
    "outputId": "a161847f-a0f1-4bb1-a840-71c32f4fa7ed",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.12)\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/pkdarabi/cardetection?dataset_version_number=5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99.8M/99.8M [00:03<00:00, 28.6MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting model files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–§–∞–π–ª—ã –¥–∞—Ç–∞—Å–µ—Ç–∞ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –ø–æ –ø—É—Ç–∏: C:\\Users\\1\\.cache\\kagglehub\\datasets\\pkdarabi\\cardetection\\versions\\5\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path_to_dataset = kagglehub.dataset_download(\"pkdarabi/cardetection\")\n",
    "print(\"–§–∞–π–ª—ã –¥–∞—Ç–∞—Å–µ—Ç–∞ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –ø–æ –ø—É—Ç–∏:\", path_to_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-BS1hTtcCQlW",
    "outputId": "8e89e0a8-3676-4cb0-94fd-3bf3d60fc4bc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.155-py3-none-any.whl (1.0 MB)\n",
      "Collecting pandas>=1.1.4\n",
      "  Downloading pandas-2.0.3-cp38-cp38-win_amd64.whl (10.8 MB)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\1\\anaconda3\\lib\\site-packages (from ultralytics) (8.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\1\\anaconda3\\lib\\site-packages (from ultralytics) (5.3.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\1\\anaconda3\\lib\\site-packages (from ultralytics) (0.19.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\1\\anaconda3\\lib\\site-packages (from ultralytics) (2.4.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\1\\anaconda3\\lib\\site-packages (from ultralytics) (5.7.2)\n",
      "Collecting ultralytics-thop>=2.0.0\n",
      "  Using cached ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\1\\anaconda3\\lib\\site-packages (from ultralytics) (3.3.2)\n",
      "Collecting tqdm>=4.64.0\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\1\\anaconda3\\lib\\site-packages (from ultralytics) (2.24.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\1\\anaconda3\\lib\\site-packages (from ultralytics) (1.5.2)\n",
      "Collecting py-cpuinfo\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Collecting numpy>=1.23.0\n",
      "  Using cached numpy-1.24.4-cp38-cp38-win_amd64.whl (14.9 MB)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\1\\anaconda3\\lib\\site-packages (from ultralytics) (4.11.0.86)\n",
      "\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\1\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2020.1)\n",
      "Collecting python-dateutil>=2.8.2\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Collecting tzdata>=2022.1\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\1\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\1\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2.11.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\1\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (0.8.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\1\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.0.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\1\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\1\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.6.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\1\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\1\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2020.6.20)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\1\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\1\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.10.0)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\1\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\1\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\1\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\1\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.0.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\1\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.1.4->ultralytics) (1.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\1\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (1.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\1\\anaconda3\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.1.0)\n",
      "Installing collected packages: numpy, python-dateutil, tzdata, pandas, ultralytics-thop, tqdm, py-cpuinfo, ultralytics\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.2\n",
      "    Uninstalling numpy-1.19.2:\n",
      "      Successfully uninstalled numpy-1.19.2\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.1\n",
      "    Uninstalling python-dateutil-2.8.1:\n",
      "      Successfully uninstalled python-dateutil-2.8.1\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.3\n",
      "    Uninstalling pandas-1.1.3:\n",
      "      Successfully uninstalled pandas-1.1.3\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.50.2\n",
      "    Uninstalling tqdm-4.50.2:\n",
      "      Successfully uninstalled tqdm-4.50.2\n",
      "Successfully installed numpy-1.24.4 pandas-2.0.3 py-cpuinfo-9.0.0 python-dateutil-2.9.0.post0 tqdm-4.67.1 tzdata-2025.2 ultralytics-8.3.155 ultralytics-thop-2.0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "huggingface-hub 0.26.1 requires fsspec>=2023.5.0, but you'll have fsspec 0.8.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUzRyO0BbnG-"
   },
   "source": [
    "#### –ü—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å –∑–Ω–∞–∫–∏ —Å –ø–æ–º–æ—â—å—é –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Ih-qGQwyFmgS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ö–∞–¥—Ä 1\n",
      "\n",
      "0: 384x640 5 persons, 2 cars, 453.3ms\n",
      "Speed: 66.4ms preprocess, 453.3ms inference, 24.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 2\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 310.8ms\n",
      "Speed: 7.0ms preprocess, 310.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 3\n",
      "\n",
      "0: 384x640 5 persons, 2 cars, 328.8ms\n",
      "Speed: 7.6ms preprocess, 328.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 4\n",
      "\n",
      "0: 384x640 5 persons, 3 cars, 1 truck, 1 traffic light, 1 skateboard, 351.2ms\n",
      "Speed: 5.2ms preprocess, 351.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 5\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 343.5ms\n",
      "Speed: 6.4ms preprocess, 343.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 6\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 1 truck, 1 kite, 333.0ms\n",
      "Speed: 5.3ms preprocess, 333.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 7\n",
      "\n",
      "0: 384x640 4 persons, 2 cars, 332.3ms\n",
      "Speed: 8.3ms preprocess, 332.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 8\n",
      "\n",
      "0: 384x640 5 persons, 2 cars, 1 truck, 350.1ms\n",
      "Speed: 5.1ms preprocess, 350.1ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 9\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 2 cars, 1 truck, 326.7ms\n",
      "Speed: 7.2ms preprocess, 326.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 10\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 1 truck, 331.3ms\n",
      "Speed: 7.2ms preprocess, 331.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 11\n",
      "\n",
      "0: 384x640 5 persons, 3 cars, 1 truck, 314.6ms\n",
      "Speed: 5.5ms preprocess, 314.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 12\n",
      "\n",
      "0: 384x640 4 persons, 3 cars, 1 truck, 383.6ms\n",
      "Speed: 5.7ms preprocess, 383.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 13\n",
      "\n",
      "0: 384x640 5 persons, 2 cars, 374.7ms\n",
      "Speed: 5.2ms preprocess, 374.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 14\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 1 truck, 383.2ms\n",
      "Speed: 7.4ms preprocess, 383.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 15\n",
      "\n",
      "0: 384x640 9 persons, 1 bicycle, 3 cars, 1 motorcycle, 1 truck, 356.0ms\n",
      "Speed: 7.4ms preprocess, 356.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 16\n",
      "\n",
      "0: 384x640 5 persons, 4 cars, 1 motorcycle, 1 truck, 317.6ms\n",
      "Speed: 5.2ms preprocess, 317.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 17\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 3 cars, 1 motorcycle, 1 truck, 355.4ms\n",
      "Speed: 5.6ms preprocess, 355.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 18\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 3 cars, 1 motorcycle, 2 trucks, 318.8ms\n",
      "Speed: 12.0ms preprocess, 318.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 19\n",
      "\n",
      "0: 384x640 4 persons, 3 cars, 1 truck, 319.6ms\n",
      "Speed: 5.4ms preprocess, 319.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 20\n",
      "\n",
      "0: 384x640 5 persons, 2 cars, 1 truck, 328.3ms\n",
      "Speed: 6.8ms preprocess, 328.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 21\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 1 car, 1 truck, 330.8ms\n",
      "Speed: 5.7ms preprocess, 330.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 22\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 1 truck, 353.8ms\n",
      "Speed: 9.4ms preprocess, 353.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 23\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 1 truck, 371.8ms\n",
      "Speed: 6.2ms preprocess, 371.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 24\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 1 truck, 429.1ms\n",
      "Speed: 7.8ms preprocess, 429.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 25\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 1 truck, 1 cow, 335.1ms\n",
      "Speed: 8.8ms preprocess, 335.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 26\n",
      "\n",
      "0: 384x640 4 persons, 1 truck, 1 cow, 394.8ms\n",
      "Speed: 9.0ms preprocess, 394.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 27\n",
      "\n",
      "0: 384x640 3 persons, 1 truck, 548.5ms\n",
      "Speed: 6.7ms preprocess, 548.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 28\n",
      "\n",
      "0: 384x640 1 person, 1 car, 394.9ms\n",
      "Speed: 5.5ms preprocess, 394.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 29\n",
      "\n",
      "0: 384x640 2 persons, 567.7ms\n",
      "Speed: 5.3ms preprocess, 567.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 30\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 1 truck, 315.9ms\n",
      "Speed: 5.7ms preprocess, 315.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 31\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 357.7ms\n",
      "Speed: 6.1ms preprocess, 357.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 32\n",
      "\n",
      "0: 384x640 1 person, 5 cars, 318.2ms\n",
      "Speed: 5.1ms preprocess, 318.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 33\n",
      "\n",
      "0: 384x640 2 persons, 5 cars, 306.9ms\n",
      "Speed: 4.8ms preprocess, 306.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 34\n",
      "\n",
      "0: 384x640 2 persons, 6 cars, 321.7ms\n",
      "Speed: 4.8ms preprocess, 321.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 35\n",
      "\n",
      "0: 384x640 2 persons, 6 cars, 1 bus, 304.8ms\n",
      "Speed: 5.4ms preprocess, 304.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 36\n",
      "\n",
      "0: 384x640 2 persons, 4 cars, 355.7ms\n",
      "Speed: 5.9ms preprocess, 355.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 37\n",
      "\n",
      "0: 384x640 2 persons, 4 cars, 415.8ms\n",
      "Speed: 5.7ms preprocess, 415.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 38\n",
      "\n",
      "0: 384x640 2 persons, 6 cars, 323.7ms\n",
      "Speed: 4.6ms preprocess, 323.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 39\n",
      "\n",
      "0: 384x640 1 person, 8 cars, 306.2ms\n",
      "Speed: 5.3ms preprocess, 306.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 40\n",
      "\n",
      "0: 384x640 1 person, 10 cars, 1 traffic light, 308.9ms\n",
      "Speed: 5.2ms preprocess, 308.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 41\n",
      "\n",
      "0: 384x640 1 person, 11 cars, 392.0ms\n",
      "Speed: 7.4ms preprocess, 392.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 42\n",
      "\n",
      "0: 384x640 7 cars, 390.8ms\n",
      "Speed: 7.7ms preprocess, 390.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 43\n",
      "\n",
      "0: 384x640 12 cars, 405.6ms\n",
      "Speed: 4.7ms preprocess, 405.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 44\n",
      "\n",
      "0: 384x640 13 cars, 390.4ms\n",
      "Speed: 6.1ms preprocess, 390.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 45\n",
      "\n",
      "0: 384x640 1 person, 11 cars, 410.5ms\n",
      "Speed: 6.1ms preprocess, 410.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 46\n",
      "\n",
      "0: 384x640 8 cars, 348.7ms\n",
      "Speed: 5.0ms preprocess, 348.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 47\n",
      "\n",
      "0: 384x640 11 cars, 342.3ms\n",
      "Speed: 5.3ms preprocess, 342.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 48\n",
      "\n",
      "0: 384x640 14 cars, 341.4ms\n",
      "Speed: 7.7ms preprocess, 341.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 49\n",
      "\n",
      "0: 384x640 13 cars, 394.6ms\n",
      "Speed: 5.3ms preprocess, 394.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 50\n",
      "\n",
      "0: 384x640 14 cars, 348.1ms\n",
      "Speed: 8.2ms preprocess, 348.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 51\n",
      "\n",
      "0: 384x640 14 cars, 337.9ms\n",
      "Speed: 4.5ms preprocess, 337.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 52\n",
      "\n",
      "0: 384x640 11 cars, 372.7ms\n",
      "Speed: 6.5ms preprocess, 372.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 53\n",
      "\n",
      "0: 384x640 1 person, 14 cars, 384.9ms\n",
      "Speed: 4.9ms preprocess, 384.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 54\n",
      "\n",
      "0: 384x640 9 cars, 358.3ms\n",
      "Speed: 7.0ms preprocess, 358.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 55\n",
      "\n",
      "0: 384x640 7 cars, 1 bus, 1 truck, 343.2ms\n",
      "Speed: 7.6ms preprocess, 343.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ö–∞–¥—Ä 56\n",
      "\n",
      "0: 384x640 9 cars, 1 truck, 323.8ms\n",
      "Speed: 6.9ms preprocess, 323.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 57\n",
      "\n",
      "0: 384x640 9 cars, 1 bus, 390.9ms\n",
      "Speed: 5.2ms preprocess, 390.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 58\n",
      "\n",
      "0: 384x640 9 cars, 384.4ms\n",
      "Speed: 10.8ms preprocess, 384.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 59\n",
      "\n",
      "0: 384x640 8 cars, 443.4ms\n",
      "Speed: 8.1ms preprocess, 443.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 60\n",
      "\n",
      "0: 384x640 9 cars, 1 truck, 445.8ms\n",
      "Speed: 5.3ms preprocess, 445.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 61\n",
      "\n",
      "0: 384x640 10 cars, 471.1ms\n",
      "Speed: 6.3ms preprocess, 471.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞\n",
      "‚úîÔ∏è –ù–∞–π–¥–µ–Ω–æ –∑–Ω–∞–∫–æ–≤: 5\n",
      "‚úçÔ∏è –°–æ—Ö—Ä–∞–Ω–∏–ª–∏ –≤ detected_signs.txt\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# –ü—É—Ç—å –∫ –≤–∏–¥–µ–æ\n",
    "video_path = '20250608_154251.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤—ã–≤–æ–¥–∞ –≤–∏–¥–µ–æ\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('output_annotated.mp4', fourcc, cap.get(5),\n",
    "                      (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "detected_signs = set()  # –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞–∫–æ–≤\n",
    "frame_num = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    frame_num += 1\n",
    "    print(f\"–ö–∞–¥—Ä {frame_num}\")\n",
    "\n",
    "    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å\n",
    "    results = model(frame)[0]\n",
    "\n",
    "    for box in results.boxes:\n",
    "        cls_id = int(box.cls[0])\n",
    "        confidence = float(box.conf[0])\n",
    "        if confidence < 0.5:\n",
    "            continue\n",
    "\n",
    "        name = model.names[cls_id]\n",
    "        detected_signs.add(name)\n",
    "\n",
    "        # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã\n",
    "        xyxy = box.xyxy[0].cpu().numpy().astype(int)\n",
    "        x1, y1, x2, y2 = xyxy\n",
    "\n",
    "        # –†–∏—Å—É–µ–º\n",
    "        label = f\"{name} {confidence:.2f}\"\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0,255,0), 2)\n",
    "        cv2.putText(frame, label, (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –º–µ—Ç–æ–∫\n",
    "with open('detected_signs.txt', 'w') as f:\n",
    "    for label in sorted(detected_signs):\n",
    "        f.write(f\"{label}\\n\")\n",
    "\n",
    "print(\"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞\")\n",
    "print(\"‚úîÔ∏è –ù–∞–π–¥–µ–Ω–æ –∑–Ω–∞–∫–æ–≤:\", len(detected_signs))\n",
    "print(\"‚úçÔ∏è –°–æ—Ö—Ä–∞–Ω–∏–ª–∏ –≤ detected_signs.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmF_-JcJbzEC"
   },
   "source": [
    "–ù–∞ –≤–∏–¥–µ–æ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –∑–Ω–∞–∫ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ –∑–Ω–∞–∫ –ø–µ—à–µ—Ö–æ–¥–Ω–æ–≥–æ –ø–µ—Ä–µ—Ö–æ–¥–∞. –ù–æ –Ω–∏ –æ–¥–∏–Ω –∏–∑ –Ω–∏—Ö –Ω–µ –±—ã–ª —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω. \n",
    "–ö–∞–∫ –æ–∫–∞–∑–∞–ª–æ—Å—å, —É –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏–∑ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –º–µ—Ç–æ–∫ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ —Å–≤–µ—Ç–æ—Ñ–æ—Ä –∏ –∑–Ω–∞–∫ \"—Å—Ç–æ–ø\".\n",
    "\n",
    "–í—ã–≤–æ–¥: –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç. –ù—É–∂–Ω–æ –æ–±—É—á–∞—Ç—å —Å–≤–æ—é –º–æ–¥–µ–ª—å"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XbUKXgAEcOFt"
   },
   "source": [
    "#### –û–±—É—á–∞–µ–º —Å–≤–æ—é –º–æ–¥–µ–ª—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g1uyVKlkF3tO",
    "outputId": "37950964-59ec-47cb-9436-f329e4b92a07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.152 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/input/cardetection/car/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=traffic-sign-trained2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/traffic-sign-trained2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
      "100% 755k/755k [00:00<00:00, 29.2MB/s]\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2121853  ultralytics.nn.modules.head.Detect           [15, [128, 256, 512]]         \n",
      "Model summary: 129 layers, 11,141,405 parameters, 11,141,389 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n",
      "100% 5.35M/5.35M [00:00<00:00, 98.1MB/s]\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.1¬±0.2 ms, read: 5.5¬±1.2 MB/s, size: 24.1 KB)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/cardetection/car/train/labels... 3530 images, 3 backgrounds, 0 corrupt: 100% 3530/3530 [00:22<00:00, 158.71it/s]\n",
      "WARNING ‚ö†Ô∏è \u001b[34m\u001b[1mtrain: \u001b[0mCache directory /kaggle/input/cardetection/car/train is not writeable, cache not saved.\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 3.7¬±2.3 MB/s, size: 20.7 KB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/cardetection/car/valid/labels... 801 images, 0 backgrounds, 0 corrupt: 100% 801/801 [00:08<00:00, 89.15it/s]\n",
      "WARNING ‚ö†Ô∏è \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/cardetection/car/valid is not writeable, cache not saved.\n",
      "Plotting labels to runs/detect/traffic-sign-trained2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000526, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/traffic-sign-trained2\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/30      3.71G     0.8503      3.567      1.181         25        640: 100% 221/221 [01:13<00:00,  3.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [00:08<00:00,  2.92it/s]\n",
      "                   all        801        944      0.405       0.52       0.41      0.333\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/30      4.51G     0.7456       1.76      1.088         35        640: 100% 221/221 [01:09<00:00,  3.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [00:07<00:00,  3.32it/s]\n",
      "                   all        801        944      0.448      0.588      0.547      0.434\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/30      4.54G     0.7419      1.459      1.081         20        640: 100% 221/221 [01:08<00:00,  3.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [00:07<00:00,  3.30it/s]\n",
      "                   all        801        944      0.601      0.681      0.673      0.532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/30      4.58G     0.7303      1.355      1.068         24        640: 100% 221/221 [01:08<00:00,  3.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [00:08<00:00,  3.23it/s]\n",
      "                   all        801        944      0.752      0.707      0.764      0.624\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/30      4.62G     0.6981      1.166      1.051         17        640: 100% 221/221 [01:08<00:00,  3.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [00:08<00:00,  3.06it/s]\n",
      "                   all        801        944      0.861      0.748      0.841      0.689\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/30      4.65G     0.6954      1.059      1.045         26        640: 100% 221/221 [01:08<00:00,  3.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [00:08<00:00,  2.93it/s]\n",
      "                   all        801        944      0.869      0.758      0.857      0.712\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/30      4.69G     0.6608      1.003      1.025         23        640: 100% 221/221 [01:08<00:00,  3.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [00:08<00:00,  3.07it/s]\n",
      "                   all        801        944      0.912      0.748      0.861      0.721\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/30      4.72G     0.6522     0.9531      1.022         24        640: 100% 221/221 [01:07<00:00,  3.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [00:08<00:00,  3.08it/s]\n",
      "                   all        801        944      0.901      0.812      0.889      0.744\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/30      4.76G     0.6514     0.8981      1.017         21        640: 100% 221/221 [01:07<00:00,  3.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [00:08<00:00,  3.05it/s]\n",
      "                   all        801        944      0.887       0.81      0.899      0.755\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/30      4.79G     0.6268      0.833      1.009         30        640: 100% 221/221 [01:07<00:00,  3.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [00:08<00:00,  3.00it/s]\n",
      "                   all        801        944      0.946      0.816      0.918      0.772\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/30      4.83G     0.6323     0.8365      1.011         26        640: 100% 221/221 [01:07<00:00,  3.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [00:08<00:00,  3.06it/s]\n",
      "                   all        801        944      0.922      0.831      0.907      0.764\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/30      4.87G     0.6135     0.8036      1.003         15        640: 100% 221/221 [01:07<00:00,  3.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [00:08<00:00,  3.06it/s]\n",
      "                   all        801        944      0.923      0.841      0.923      0.781\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/30       4.9G     0.6196     0.7545     0.9981         30        640: 100% 221/221 [01:07<00:00,  3.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [00:08<00:00,  3.02it/s]\n",
      "                   all        801        944      0.925      0.874      0.936      0.787\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/30      4.94G     0.5927     0.7409      0.987         24        640: 100% 221/221 [01:08<00:00,  3.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [00:08<00:00,  3.06it/s]\n",
      "                   all        801        944      0.931      0.866      0.928      0.788\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/30      4.98G     0.5877     0.7024     0.9914         22        640: 100% 221/221 [01:07<00:00,  3.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [00:08<00:00,  3.06it/s]\n",
      "                   all        801        944      0.953      0.885      0.943      0.798\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/30      5.01G     0.5869     0.7021     0.9903         24        640: 100% 221/221 [01:07<00:00,  3.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [00:08<00:00,  3.07it/s]\n",
      "                   all        801        944      0.936      0.892      0.947      0.813\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/30      5.05G     0.5808     0.6818     0.9853         21        640: 100% 221/221 [01:07<00:00,  3.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [00:08<00:00,  3.13it/s]\n",
      "                   all        801        944      0.962      0.886      0.955      0.813\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/30      5.08G     0.5648     0.6582     0.9819         24        640: 100% 221/221 [01:07<00:00,  3.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [00:08<00:00,  3.17it/s]\n",
      "                   all        801        944      0.927      0.895      0.948      0.802\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/30      5.12G     0.5609     0.6622      0.974         25        640: 100% 221/221 [01:07<00:00,  3.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [00:08<00:00,  3.22it/s]\n",
      "                   all        801        944      0.935      0.894      0.944      0.811\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/30      5.16G     0.5586     0.6266     0.9722         23        640: 100% 221/221 [01:07<00:00,  3.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [00:08<00:00,  3.24it/s]\n",
      "                   all        801        944      0.965      0.878      0.958      0.822\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      21/30       5.2G      0.554     0.4145     0.9475         12        640: 100% 221/221 [01:06<00:00,  3.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [00:07<00:00,  3.38it/s]\n",
      "                   all        801        944       0.93        0.9      0.953      0.812\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      22/30      5.23G     0.5491     0.3916     0.9427         18        640: 100% 221/221 [01:04<00:00,  3.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [00:08<00:00,  3.09it/s]\n",
      "                   all        801        944      0.949       0.92      0.958      0.819\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      23/30      5.27G     0.5347     0.3758     0.9304         12        640: 100% 221/221 [01:04<00:00,  3.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [00:08<00:00,  3.12it/s]\n",
      "                   all        801        944      0.954      0.908      0.963      0.823\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      24/30       5.3G     0.5329     0.3628     0.9301         10        640: 100% 221/221 [01:04<00:00,  3.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [00:07<00:00,  3.37it/s]\n",
      "                   all        801        944      0.962      0.919      0.966      0.831\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      25/30      5.34G     0.5222     0.3449     0.9236         12        640: 100% 221/221 [01:04<00:00,  3.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [00:08<00:00,  3.06it/s]\n",
      "                   all        801        944      0.955      0.924      0.964       0.83\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      26/30      5.38G     0.5115     0.3377      0.924         10        640: 100% 221/221 [01:04<00:00,  3.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [00:08<00:00,  3.07it/s]\n",
      "                   all        801        944       0.95      0.928      0.967      0.834\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      27/30      5.42G     0.5034     0.3242     0.9122         15        640: 100% 221/221 [01:04<00:00,  3.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [00:07<00:00,  3.41it/s]\n",
      "                   all        801        944      0.966      0.911      0.967      0.837\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      28/30      5.45G     0.4993     0.3132     0.9102         10        640: 100% 221/221 [01:04<00:00,  3.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [00:08<00:00,  3.06it/s]\n",
      "                   all        801        944      0.958      0.914      0.966      0.838\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      29/30      5.49G       0.49     0.3022     0.9081         12        640: 100% 221/221 [01:04<00:00,  3.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [00:08<00:00,  3.09it/s]\n",
      "                   all        801        944       0.94      0.932      0.967      0.838\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      30/30      5.52G     0.4804     0.2959     0.8994         13        640: 100% 221/221 [01:04<00:00,  3.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [00:08<00:00,  3.24it/s]\n",
      "                   all        801        944      0.942      0.934      0.967      0.837\n",
      "\n",
      "30 epochs completed in 0.633 hours.\n",
      "Optimizer stripped from runs/detect/traffic-sign-trained2/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from runs/detect/traffic-sign-trained2/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating runs/detect/traffic-sign-trained2/weights/best.pt...\n",
      "Ultralytics 8.3.152 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "Model summary (fused): 72 layers, 11,131,389 parameters, 0 gradients, 28.5 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [00:09<00:00,  2.77it/s]\n",
      "                   all        801        944       0.94      0.931      0.967      0.837\n",
      "           Green Light         87        122      0.856      0.782      0.878      0.539\n",
      "             Red Light         74        108      0.777      0.808      0.844      0.513\n",
      "       Speed Limit 100         52         52      0.963      0.994      0.993      0.898\n",
      "       Speed Limit 110         17         17      0.947      0.941      0.975      0.902\n",
      "       Speed Limit 120         60         60      0.987          1      0.995      0.921\n",
      "        Speed Limit 20         56         56      0.945      0.982      0.987      0.878\n",
      "        Speed Limit 30         71         74      0.919      0.973       0.99      0.921\n",
      "        Speed Limit 40         53         55      0.929      0.927      0.986      0.875\n",
      "        Speed Limit 50         68         71      0.985      0.901      0.975      0.882\n",
      "        Speed Limit 60         76         76      0.986      0.933      0.979      0.889\n",
      "        Speed Limit 70         78         78      0.946      0.987      0.985      0.897\n",
      "        Speed Limit 80         56         56      0.964      0.982      0.993      0.885\n",
      "        Speed Limit 90         38         38       0.97       0.84      0.965      0.786\n",
      "                  Stop         81         81      0.992      0.988      0.993      0.937\n",
      "Speed: 0.2ms preprocess, 4.5ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/traffic-sign-trained2\u001b[0m\n",
      "üí° Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect \\\n",
    "  mode=train \\\n",
    "  model=yolov8s.pt \\\n",
    "  data=/kaggle/input/cardetection/car/data.yaml \\\n",
    "  epochs=30 \\\n",
    "  imgsz=640 \\\n",
    "  batch=16 \\\n",
    "  name=traffic-sign-trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XQSr9TboZPpi",
    "outputId": "ad240f86-bf08-4f65-b12a-ceff51818dd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ö–∞–¥—Ä 1\n",
      "\n",
      "0: 384x640 (no detections), 389.7ms\n",
      "Speed: 9.1ms preprocess, 389.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 2\n",
      "\n",
      "0: 384x640 (no detections), 329.2ms\n",
      "Speed: 7.0ms preprocess, 329.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 3\n",
      "\n",
      "0: 384x640 (no detections), 305.8ms\n",
      "Speed: 4.9ms preprocess, 305.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 4\n",
      "\n",
      "0: 384x640 (no detections), 347.7ms\n",
      "Speed: 5.4ms preprocess, 347.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 5\n",
      "\n",
      "0: 384x640 (no detections), 295.2ms\n",
      "Speed: 6.2ms preprocess, 295.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 6\n",
      "\n",
      "0: 384x640 (no detections), 300.4ms\n",
      "Speed: 4.7ms preprocess, 300.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 7\n",
      "\n",
      "0: 384x640 (no detections), 389.6ms\n",
      "Speed: 5.4ms preprocess, 389.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 8\n",
      "\n",
      "0: 384x640 (no detections), 332.3ms\n",
      "Speed: 6.1ms preprocess, 332.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 9\n",
      "\n",
      "0: 384x640 (no detections), 291.3ms\n",
      "Speed: 5.4ms preprocess, 291.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 10\n",
      "\n",
      "0: 384x640 (no detections), 340.5ms\n",
      "Speed: 5.3ms preprocess, 340.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 11\n",
      "\n",
      "0: 384x640 (no detections), 295.9ms\n",
      "Speed: 5.2ms preprocess, 295.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 12\n",
      "\n",
      "0: 384x640 (no detections), 294.7ms\n",
      "Speed: 4.2ms preprocess, 294.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 13\n",
      "\n",
      "0: 384x640 1 Red Light, 311.6ms\n",
      "Speed: 5.1ms preprocess, 311.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 14\n",
      "\n",
      "0: 384x640 (no detections), 298.6ms\n",
      "Speed: 6.1ms preprocess, 298.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 15\n",
      "\n",
      "0: 384x640 (no detections), 291.6ms\n",
      "Speed: 4.8ms preprocess, 291.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 16\n",
      "\n",
      "0: 384x640 (no detections), 300.6ms\n",
      "Speed: 5.0ms preprocess, 300.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 17\n",
      "\n",
      "0: 384x640 (no detections), 364.3ms\n",
      "Speed: 5.7ms preprocess, 364.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 18\n",
      "\n",
      "0: 384x640 (no detections), 337.1ms\n",
      "Speed: 4.5ms preprocess, 337.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 19\n",
      "\n",
      "0: 384x640 (no detections), 356.3ms\n",
      "Speed: 4.7ms preprocess, 356.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 20\n",
      "\n",
      "0: 384x640 1 Red Light, 324.3ms\n",
      "Speed: 4.5ms preprocess, 324.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 21\n",
      "\n",
      "0: 384x640 1 Red Light, 346.0ms\n",
      "Speed: 5.8ms preprocess, 346.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 22\n",
      "\n",
      "0: 384x640 1 Red Light, 308.1ms\n",
      "Speed: 4.5ms preprocess, 308.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 23\n",
      "\n",
      "0: 384x640 1 Red Light, 302.0ms\n",
      "Speed: 6.9ms preprocess, 302.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 24\n",
      "\n",
      "0: 384x640 1 Red Light, 290.1ms\n",
      "Speed: 4.7ms preprocess, 290.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 25\n",
      "\n",
      "0: 384x640 1 Red Light, 291.8ms\n",
      "Speed: 4.4ms preprocess, 291.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 26\n",
      "\n",
      "0: 384x640 1 Red Light, 399.5ms\n",
      "Speed: 8.0ms preprocess, 399.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 27\n",
      "\n",
      "0: 384x640 1 Red Light, 313.3ms\n",
      "Speed: 4.3ms preprocess, 313.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 28\n",
      "\n",
      "0: 384x640 1 Red Light, 305.9ms\n",
      "Speed: 4.7ms preprocess, 305.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 29\n",
      "\n",
      "0: 384x640 1 Red Light, 435.6ms\n",
      "Speed: 6.6ms preprocess, 435.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 30\n",
      "\n",
      "0: 384x640 1 Red Light, 360.6ms\n",
      "Speed: 4.3ms preprocess, 360.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 31\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 327.8ms\n",
      "Speed: 3.9ms preprocess, 327.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 32\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 443.8ms\n",
      "Speed: 9.2ms preprocess, 443.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 33\n",
      "\n",
      "0: 384x640 1 Red Light, 376.9ms\n",
      "Speed: 5.4ms preprocess, 376.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 34\n",
      "\n",
      "0: 384x640 1 Red Light, 548.7ms\n",
      "Speed: 14.0ms preprocess, 548.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 35\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 338.8ms\n",
      "Speed: 5.4ms preprocess, 338.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 36\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 415.1ms\n",
      "Speed: 3.9ms preprocess, 415.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 37\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 374.0ms\n",
      "Speed: 4.4ms preprocess, 374.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 38\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 384.2ms\n",
      "Speed: 6.0ms preprocess, 384.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 39\n",
      "\n",
      "0: 384x640 2 Red Lights, 1 Stop, 362.2ms\n",
      "Speed: 6.3ms preprocess, 362.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 40\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 320.8ms\n",
      "Speed: 9.4ms preprocess, 320.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 41\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 321.4ms\n",
      "Speed: 4.1ms preprocess, 321.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 42\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 299.3ms\n",
      "Speed: 4.0ms preprocess, 299.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 43\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 358.3ms\n",
      "Speed: 5.1ms preprocess, 358.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 44\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 342.3ms\n",
      "Speed: 4.6ms preprocess, 342.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 45\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 344.3ms\n",
      "Speed: 4.2ms preprocess, 344.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 46\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 339.6ms\n",
      "Speed: 5.2ms preprocess, 339.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 47\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 347.7ms\n",
      "Speed: 4.2ms preprocess, 347.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 48\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 313.6ms\n",
      "Speed: 4.2ms preprocess, 313.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 49\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 324.4ms\n",
      "Speed: 5.0ms preprocess, 324.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 50\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 348.0ms\n",
      "Speed: 4.4ms preprocess, 348.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 51\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 323.1ms\n",
      "Speed: 4.7ms preprocess, 323.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 52\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 329.2ms\n",
      "Speed: 5.7ms preprocess, 329.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 53\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 344.6ms\n",
      "Speed: 4.0ms preprocess, 344.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 54\n",
      "\n",
      "0: 384x640 2 Red Lights, 1 Stop, 296.7ms\n",
      "Speed: 4.0ms preprocess, 296.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 55\n",
      "\n",
      "0: 384x640 2 Red Lights, 1 Stop, 287.2ms\n",
      "Speed: 4.0ms preprocess, 287.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 56\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 297.3ms\n",
      "Speed: 4.0ms preprocess, 297.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 57\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 320.9ms\n",
      "Speed: 4.2ms preprocess, 320.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 58\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 Red Light, 1 Stop, 317.2ms\n",
      "Speed: 4.6ms preprocess, 317.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 59\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 317.8ms\n",
      "Speed: 3.8ms preprocess, 317.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 60\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 339.1ms\n",
      "Speed: 5.5ms preprocess, 339.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 61\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 303.8ms\n",
      "Speed: 6.1ms preprocess, 303.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 62\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 343.9ms\n",
      "Speed: 6.1ms preprocess, 343.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 63\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 329.4ms\n",
      "Speed: 3.8ms preprocess, 329.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 64\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 363.8ms\n",
      "Speed: 4.6ms preprocess, 363.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 65\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 386.0ms\n",
      "Speed: 3.8ms preprocess, 386.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 66\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 302.2ms\n",
      "Speed: 5.0ms preprocess, 302.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 67\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 337.8ms\n",
      "Speed: 3.9ms preprocess, 337.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 68\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 314.9ms\n",
      "Speed: 4.0ms preprocess, 314.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 69\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 330.8ms\n",
      "Speed: 7.0ms preprocess, 330.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 70\n",
      "\n",
      "0: 384x640 2 Red Lights, 1 Stop, 358.5ms\n",
      "Speed: 4.1ms preprocess, 358.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 71\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 345.2ms\n",
      "Speed: 4.9ms preprocess, 345.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 72\n",
      "\n",
      "0: 384x640 2 Red Lights, 1 Stop, 289.3ms\n",
      "Speed: 5.3ms preprocess, 289.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 73\n",
      "\n",
      "0: 384x640 2 Red Lights, 1 Stop, 346.2ms\n",
      "Speed: 4.5ms preprocess, 346.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 74\n",
      "\n",
      "0: 384x640 2 Red Lights, 1 Stop, 363.3ms\n",
      "Speed: 4.9ms preprocess, 363.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 75\n",
      "\n",
      "0: 384x640 2 Red Lights, 1 Stop, 307.5ms\n",
      "Speed: 4.7ms preprocess, 307.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 76\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 352.1ms\n",
      "Speed: 4.9ms preprocess, 352.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 77\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 333.2ms\n",
      "Speed: 4.1ms preprocess, 333.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 78\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 371.1ms\n",
      "Speed: 5.1ms preprocess, 371.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 79\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 329.3ms\n",
      "Speed: 5.0ms preprocess, 329.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 80\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 363.5ms\n",
      "Speed: 4.9ms preprocess, 363.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 81\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 340.0ms\n",
      "Speed: 4.2ms preprocess, 340.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 82\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 366.4ms\n",
      "Speed: 4.7ms preprocess, 366.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 83\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 308.4ms\n",
      "Speed: 4.0ms preprocess, 308.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 84\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 291.2ms\n",
      "Speed: 4.0ms preprocess, 291.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 85\n",
      "\n",
      "0: 384x640 2 Red Lights, 1 Stop, 326.3ms\n",
      "Speed: 4.8ms preprocess, 326.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 86\n",
      "\n",
      "0: 384x640 2 Red Lights, 1 Stop, 319.6ms\n",
      "Speed: 10.1ms preprocess, 319.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 87\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 325.3ms\n",
      "Speed: 4.1ms preprocess, 325.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 88\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 328.7ms\n",
      "Speed: 6.0ms preprocess, 328.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 89\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 326.1ms\n",
      "Speed: 3.9ms preprocess, 326.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 90\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 291.4ms\n",
      "Speed: 3.9ms preprocess, 291.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 91\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 336.8ms\n",
      "Speed: 4.3ms preprocess, 336.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 92\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 355.6ms\n",
      "Speed: 5.5ms preprocess, 355.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 93\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 316.3ms\n",
      "Speed: 4.0ms preprocess, 316.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 94\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 375.7ms\n",
      "Speed: 5.5ms preprocess, 375.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 95\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 311.6ms\n",
      "Speed: 4.2ms preprocess, 311.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 96\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 310.3ms\n",
      "Speed: 4.0ms preprocess, 310.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 97\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 356.4ms\n",
      "Speed: 4.5ms preprocess, 356.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 98\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 353.3ms\n",
      "Speed: 4.2ms preprocess, 353.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 99\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 354.4ms\n",
      "Speed: 3.9ms preprocess, 354.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 100\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 318.1ms\n",
      "Speed: 4.0ms preprocess, 318.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 101\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 300.7ms\n",
      "Speed: 5.0ms preprocess, 300.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 102\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 345.2ms\n",
      "Speed: 4.5ms preprocess, 345.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 103\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 336.9ms\n",
      "Speed: 3.9ms preprocess, 336.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 104\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 285.5ms\n",
      "Speed: 3.9ms preprocess, 285.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 105\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 320.4ms\n",
      "Speed: 4.6ms preprocess, 320.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 106\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 335.1ms\n",
      "Speed: 4.6ms preprocess, 335.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 107\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 312.7ms\n",
      "Speed: 4.1ms preprocess, 312.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 108\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 350.7ms\n",
      "Speed: 4.6ms preprocess, 350.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 109\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 305.0ms\n",
      "Speed: 4.0ms preprocess, 305.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 110\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 280.5ms\n",
      "Speed: 3.9ms preprocess, 280.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 111\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 300.0ms\n",
      "Speed: 4.0ms preprocess, 300.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 112\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 305.6ms\n",
      "Speed: 3.8ms preprocess, 305.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 113\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 281.9ms\n",
      "Speed: 4.0ms preprocess, 281.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ö–∞–¥—Ä 114\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 282.9ms\n",
      "Speed: 4.3ms preprocess, 282.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 115\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 303.8ms\n",
      "Speed: 3.7ms preprocess, 303.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 116\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 304.0ms\n",
      "Speed: 4.2ms preprocess, 304.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 117\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 287.2ms\n",
      "Speed: 4.7ms preprocess, 287.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 118\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 286.7ms\n",
      "Speed: 3.8ms preprocess, 286.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 119\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 282.6ms\n",
      "Speed: 6.4ms preprocess, 282.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 120\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 280.3ms\n",
      "Speed: 5.1ms preprocess, 280.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 121\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 285.6ms\n",
      "Speed: 5.0ms preprocess, 285.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 122\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 309.4ms\n",
      "Speed: 5.6ms preprocess, 309.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 123\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 308.0ms\n",
      "Speed: 5.8ms preprocess, 308.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 124\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 344.3ms\n",
      "Speed: 5.6ms preprocess, 344.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 125\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 366.3ms\n",
      "Speed: 5.0ms preprocess, 366.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 126\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 321.8ms\n",
      "Speed: 5.4ms preprocess, 321.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 127\n",
      "\n",
      "0: 384x640 1 Red Light, 1 Stop, 403.7ms\n",
      "Speed: 17.8ms preprocess, 403.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 128\n",
      "\n",
      "0: 384x640 1 Green Light, 1 Red Light, 1 Stop, 410.9ms\n",
      "Speed: 6.1ms preprocess, 410.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 129\n",
      "\n",
      "0: 384x640 1 Green Light, 1 Stop, 382.2ms\n",
      "Speed: 6.1ms preprocess, 382.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 130\n",
      "\n",
      "0: 384x640 1 Green Light, 1 Stop, 388.1ms\n",
      "Speed: 4.9ms preprocess, 388.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 131\n",
      "\n",
      "0: 384x640 1 Green Light, 1 Stop, 307.3ms\n",
      "Speed: 4.9ms preprocess, 307.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 132\n",
      "\n",
      "0: 384x640 1 Green Light, 1 Stop, 290.2ms\n",
      "Speed: 6.2ms preprocess, 290.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 133\n",
      "\n",
      "0: 384x640 1 Green Light, 1 Stop, 320.5ms\n",
      "Speed: 3.9ms preprocess, 320.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 134\n",
      "\n",
      "0: 384x640 1 Green Light, 1 Stop, 370.1ms\n",
      "Speed: 10.3ms preprocess, 370.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 135\n",
      "\n",
      "0: 384x640 1 Green Light, 1 Stop, 438.9ms\n",
      "Speed: 6.5ms preprocess, 438.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 136\n",
      "\n",
      "0: 384x640 1 Green Light, 1 Stop, 331.3ms\n",
      "Speed: 14.4ms preprocess, 331.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 137\n",
      "\n",
      "0: 384x640 1 Green Light, 1 Stop, 299.1ms\n",
      "Speed: 3.9ms preprocess, 299.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 138\n",
      "\n",
      "0: 384x640 1 Green Light, 1 Stop, 282.1ms\n",
      "Speed: 3.9ms preprocess, 282.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 139\n",
      "\n",
      "0: 384x640 1 Green Light, 310.2ms\n",
      "Speed: 4.7ms preprocess, 310.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 140\n",
      "\n",
      "0: 384x640 1 Green Light, 366.4ms\n",
      "Speed: 4.1ms preprocess, 366.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 141\n",
      "\n",
      "0: 384x640 1 Green Light, 1 Stop, 326.9ms\n",
      "Speed: 4.1ms preprocess, 326.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 142\n",
      "\n",
      "0: 384x640 1 Green Light, 321.4ms\n",
      "Speed: 5.9ms preprocess, 321.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 143\n",
      "\n",
      "0: 384x640 1 Green Light, 1 Stop, 329.1ms\n",
      "Speed: 5.6ms preprocess, 329.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 144\n",
      "\n",
      "0: 384x640 1 Green Light, 1 Stop, 297.6ms\n",
      "Speed: 3.9ms preprocess, 297.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 145\n",
      "\n",
      "0: 384x640 1 Green Light, 326.7ms\n",
      "Speed: 3.9ms preprocess, 326.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 146\n",
      "\n",
      "0: 384x640 1 Green Light, 287.2ms\n",
      "Speed: 4.2ms preprocess, 287.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 147\n",
      "\n",
      "0: 384x640 1 Green Light, 298.2ms\n",
      "Speed: 4.3ms preprocess, 298.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 148\n",
      "\n",
      "0: 384x640 1 Green Light, 293.8ms\n",
      "Speed: 5.0ms preprocess, 293.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "–ö–∞–¥—Ä 149\n",
      "\n",
      "0: 384x640 1 Green Light, 297.8ms\n",
      "Speed: 4.8ms preprocess, 297.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞\n",
      "‚úîÔ∏è –ù–∞–π–¥–µ–Ω–æ –∑–Ω–∞–∫–æ–≤: 3\n",
      "‚úçÔ∏è –°–æ—Ö—Ä–∞–Ω–∏–ª–∏ –≤ detected_signs.txt\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "model = YOLO('best.pt')\n",
    "\n",
    "# –ü—É—Ç—å –∫ –≤–∏–¥–µ–æ\n",
    "video_path = 'samplee.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤—ã–≤–æ–¥–∞ –≤–∏–¥–µ–æ\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('output_annotated_3.mp4', fourcc, cap.get(5),\n",
    "                      (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "detected_signs = set()  # –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞–∫–æ–≤\n",
    "frame_num = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    frame_num += 1\n",
    "    print(f\"–ö–∞–¥—Ä {frame_num}\")\n",
    "\n",
    "    # üîç –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å\n",
    "    results = model(frame)[0]\n",
    "\n",
    "    for box in results.boxes:\n",
    "        cls_id = int(box.cls[0])\n",
    "        confidence = float(box.conf[0])\n",
    "        if confidence < 0.5:\n",
    "            continue\n",
    "\n",
    "        name = model.names[cls_id]\n",
    "        detected_signs.add(name)\n",
    "\n",
    "        # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã\n",
    "        xyxy = box.xyxy[0].cpu().numpy().astype(int)\n",
    "        x1, y1, x2, y2 = xyxy\n",
    "\n",
    "        # –†–∏—Å—É–µ–º\n",
    "        label = f\"{name} {confidence:.2f}\"\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0,255,0), 2)\n",
    "        cv2.putText(frame, label, (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –º–µ—Ç–æ–∫\n",
    "with open('detected_signs.txt', 'w') as f:\n",
    "    for label in sorted(detected_signs):\n",
    "        f.write(f\"{label}\\n\")\n",
    "\n",
    "print(\"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞\")\n",
    "print(\"‚úîÔ∏è –ù–∞–π–¥–µ–Ω–æ –∑–Ω–∞–∫–æ–≤:\", len(detected_signs))\n",
    "print(\"‚úçÔ∏è –°–æ—Ö—Ä–∞–Ω–∏–ª–∏ –≤ detected_signs.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–æ–¥–µ–ª—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–ª–∞ –∑–Ω–∞–∫–∏ –Ω–∞ –≤–∏–¥–µ–æ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í—ã–≤–µ–¥–µ–º –æ—Ç–¥–µ–ª—å–Ω–æ –º–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "77sIeH4kaSBZ",
    "outputId": "1f157422-8f3a-46d8-c111-f672044e9301"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.152 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "Model summary (fused): 72 layers, 11,131,389 parameters, 0 gradients, 28.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 3.8¬±1.6 MB/s, size: 20.7 KB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/cardetection/car/test/labels... 638 images, 1 backgrounds, 0 corrupt: 100% 638/638 [00:07<00:00, 80.12it/s]\n",
      "WARNING ‚ö†Ô∏è \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/cardetection/car/test is not writeable, cache not saved.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 40/40 [00:08<00:00,  4.50it/s]\n",
      "                   all        638        770       0.93      0.903      0.947      0.811\n",
      "           Green Light         77        110      0.878      0.851      0.913       0.58\n",
      "             Red Light         71         94       0.85      0.724      0.812      0.491\n",
      "        Speed Limit 10          2          3      0.633      0.667      0.775      0.637\n",
      "       Speed Limit 100         45         46      0.945          1      0.992      0.867\n",
      "       Speed Limit 110         21         21          1      0.903       0.93      0.826\n",
      "       Speed Limit 120         40         44      0.939          1      0.994      0.893\n",
      "        Speed Limit 20         46         46      0.983      0.957      0.978      0.884\n",
      "        Speed Limit 30         60         60      0.964      0.882      0.979      0.884\n",
      "        Speed Limit 40         51         53      0.981      0.978      0.986      0.878\n",
      "        Speed Limit 50         47         50      0.931       0.88      0.952      0.866\n",
      "        Speed Limit 60         45         45      0.956      0.911      0.961      0.845\n",
      "        Speed Limit 70         52         53      0.962      0.953       0.98      0.878\n",
      "        Speed Limit 80         60         61      0.943      0.967      0.992       0.89\n",
      "        Speed Limit 90         33         34          1       0.87      0.963      0.816\n",
      "                  Stop         50         50      0.979          1      0.995      0.929\n",
      "Speed: 0.7ms preprocess, 8.8ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
      "üí° Learn more at https://docs.ultralytics.com/modes/val\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect \\\n",
    "  mode=val \\\n",
    "  model=runs/detect/traffic-sign-trained2/weights/best.pt \\\n",
    "  data=/kaggle/input/cardetection/car/data.yaml \\\n",
    "  split=test"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
